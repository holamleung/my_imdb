{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1fa240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from urllib.request import urlretrieve\n",
    "from getpass import getpass\n",
    "\n",
    "import pandas as pd\n",
    "from mysql.connector import Error, connect, errorcode"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0a76ea3",
   "metadata": {},
   "source": [
    "## Prepare: Setting parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad34efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurate MySQL connection\n",
    "\n",
    "# input username and password when run this block\n",
    "CONFIG = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"user\": input(\"Username: \"),\n",
    "    \"password\": getpass(\"Password: \"),\n",
    "}\n",
    "\n",
    "# MySQL database name\n",
    "DB_NAME = \"my_imdb\"\n",
    "\n",
    "# Datasets folder location\n",
    "DATASET_LOC = os.path.abspath(\"datasets\")\n",
    "\n",
    "# List of datasets download links\n",
    "URLS = [\n",
    "    \"https://datasets.imdbws.com/title.basics.tsv.gz\",\n",
    "    \"https://datasets.imdbws.com/name.basics.tsv.gz\",\n",
    "    \"https://datasets.imdbws.com/title.ratings.tsv.gz\",\n",
    "    \"https://datasets.imdbws.com/title.crew.tsv.gz\"\n",
    "    ]\n",
    "\n",
    "# Whether overwrite existing datasets\n",
    "OVERWRITE = input(\"Overwrite existing files? (y/n) \").lower()\n",
    "if OVERWRITE == \"y\":\n",
    "    OVERWRITE = True\n",
    "elif OVERWRITE == \"n\":\n",
    "    OVERWRITE = False\n",
    "else:\n",
    "    sys.exit(\"Invalid input, please try again.\")\n",
    "\n",
    "# Queries to create tables\n",
    "CREATES = {}\n",
    "CREATES[\"title_basics\"] = \"\"\"\n",
    "    CREATE TABLE title_basics (\n",
    "        tconst varchar(20) NOT NULL,\n",
    "        titleType varchar(20),\n",
    "        primaryTitle varchar(1000),\n",
    "        originalTItle varchar(1000),\n",
    "        isAdult bool,\n",
    "        startYear smallint,\n",
    "        endYear smallint,\n",
    "        runtimeMinutes int,\n",
    "        genres varchar(255),\n",
    "        PRIMARY KEY (tconst)\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "CREATES[\"name_basics\"] = \"\"\"\n",
    "    CREATE TABLE name_basics (\n",
    "        nconst varchar(20) NOT NULL,\n",
    "        primaryName varchar(50),\n",
    "        birthYear smallint,\n",
    "        deathYear smallint,\n",
    "        primaryProfession varchar(100),\n",
    "        knownForTitles varchar(100),\n",
    "        PRIMARY KEY (nconst),\n",
    "        FOREIGN KEY (knownForTitles)\n",
    "            REFERENCES title_basics(tconst)\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "CREATES[\"title_ratings\"] = \"\"\"\n",
    "    CREATE TABLE title_ratings (\n",
    "        tconst varchar(20) NOT NULL,\n",
    "        averageRating decimal(3, 1),\n",
    "        numVotes int,\n",
    "        PRIMARY KEY (tconst),\n",
    "        FOREIGN KEY (tconst)\n",
    "            REFERENCES title_basics(tconst)\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "CREATES[\"title_crew\"] = \"\"\"\n",
    "    CREATE TABLE title_crew (\n",
    "        tconst varchar(20) NOT NULL,\n",
    "        directors varchar(20),\n",
    "        writers varchar(20),\n",
    "        PRIMARY KEY (tconst),\n",
    "        FOREIGN KEY (tconst)\n",
    "            REFERENCES title_basics(tconst),\n",
    "        FOREIGN KEY (directors)\n",
    "            REFERENCES name_basics(nconst),\n",
    "        FOREIGN KEY (writers)\n",
    "            REFERENCES name_basics(nconst)\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "# Queries of inserting records\n",
    "INSERTS = {}\n",
    "INSERTS[\"title_basics\"] = \"\"\"\n",
    "    INSERT INTO title_basics\n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "\n",
    "INSERTS[\"name_basics\"] = \"\"\"\n",
    "    INSERT INTO name_basics\n",
    "    VALUES (%s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "\n",
    "INSERTS[\"title_ratings\"] = \"\"\"\n",
    "    INSERT INTO title_ratings\n",
    "    VALUES (%s, %s, %s)\n",
    "    \"\"\"\n",
    "\n",
    "INSERTS[\"title_crew\"] = \"\"\"\n",
    "    INSERT INTO title_crew\n",
    "    VALUES (%s, %s, %s)\n",
    "    \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e096429f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(DATASET_LOC):\n",
    "    os.makedirs(DATASET_LOC)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4f71bd3",
   "metadata": {},
   "source": [
    "## Part 1: Donwload and Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424a5586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prompt skip overwriting existing file\n",
    "def check_overwrite(filename):\n",
    "    if os.path.exists(os.path.join(DATASET_LOC, filename)):\n",
    "        return OVERWRITE\n",
    "    else:\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd778f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Filename class to conatins attributes of different filenames\n",
    "class Filename:\n",
    "    def __init__(self, name, url, zip, tsv, csv, small):\n",
    "        self.name = name\n",
    "        self.url = url\n",
    "        self.zip = zip\n",
    "        self.tsv = tsv \n",
    "        self.csv = csv\n",
    "        self.small = small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28c6139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a dictionary of filenames from the donwload link\n",
    "filenames = {}\n",
    "for url in URLS:\n",
    "    zip = url.rsplit(\"/\", 1)[-1]\n",
    "    tsv_matches = re.search(r\"^(.+)\\.(.+)\\.(tsv).gz$\", zip)\n",
    "    name = f\"{tsv_matches[1]}_{tsv_matches[2]}\"\n",
    "    tsv = os.path.join(name + os.extsep + \"tsv\")\n",
    "    csv = os.path.join(name + os.extsep + \"csv\")\n",
    "    small = os.path.join(name + \"_s\" + os.extsep + \"csv\")\n",
    "    filenames[name] = Filename(name, url, zip, tsv, csv, small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b3d80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Donwload datasets files from imdb website\n",
    "for filename in filenames.values():\n",
    "    if check_overwrite(filename.zip) == False:\n",
    "        continue\n",
    "    try:\n",
    "        urlretrieve(filename.url, os.path.join(DATASET_LOC, filename.zip))\n",
    "        print(f\"Downloaded '{filename.zip}' to {DATASET_LOC}\")\n",
    "    except Error as e:\n",
    "        print(f\"Download '{filename.zip}' fail\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b33729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip and rename the tsv files\n",
    "for filename in filenames.values():\n",
    "    if check_overwrite(filename.tsv) == False:\n",
    "        continue\n",
    "    try:\n",
    "        with gzip.open(os.path.join(DATASET_LOC, filename.zip), \"rb\") as f_in:\n",
    "            with open(os.path.join(DATASET_LOC, filename.tsv), \"wb\") as f_out:\n",
    "                f_out.write(f_in.read())\n",
    "                print(f\"Extracted {filename.tsv} to {DATASET_LOC}\")\n",
    "    except Error as e:\n",
    "        print(f'Extract {filename.zip} Failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6714c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning and convert tsv to csv file\n",
    "for filename in filenames.values():\n",
    "    imdb_table = pd.read_table(os.path.join(DATASET_LOC, filename.tsv), sep=\"\\t\")\n",
    "    \n",
    "    # Data Cleaning for title_basics\n",
    "    if filename.name == \"title_basics\":\n",
    "\n",
    "        # Locate all rows with primaryTilte issues\n",
    "        title_issue_df = imdb_table[imdb_table[\"primaryTitle\"].str.contains(r\".+\\t.+\") == True]\n",
    "        \n",
    "        # If rows with primaryTilte issues exit\n",
    "        if title_issue_df.shape[0] > 0:\n",
    "            rows_fixed = 0\n",
    "            for index, row in title_issue_df.iterrows():\n",
    "                values = row.values.flatten().tolist()\n",
    "                \n",
    "                # Split the string to two columns\n",
    "                clean_titles = values[2].split(\"\\t\")\n",
    "                values[2] = clean_titles[0]\n",
    "                values.insert(3, clean_titles[1])\n",
    "\n",
    "                # Removed unnecessary NaN value at the end\n",
    "                values.pop()\n",
    "\n",
    "                # Replace the row in the table\n",
    "                imdb_table[imdb_table[\"tconst\"] == values[0]] = values\n",
    "                rows_fixed += 1\n",
    "            print(f\"Fixed {rows_fixed} row\")\n",
    "        \n",
    "    # Export csv\n",
    "    if check_overwrite(filename.csv) == False:\n",
    "        continue\n",
    "    try:\n",
    "        imdb_table.to_csv(os.path.join(DATASET_LOC, filename.csv), index=False)\n",
    "        print(f\"Converted {filename.tsv} to {filename.csv}\")\n",
    "    except:\n",
    "        print(f\"Convert {filename.tsv} failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7ad685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional\n",
    "# Reduce rows in files and convert to csv\n",
    "for filename in filenames.values():\n",
    "    if filename.name == \"name_basics\":\n",
    "        continue\n",
    "    else:\n",
    "        imdb_table = pd.read_table(os.path.join(DATASET_LOC, filename.tsv), sep=\"\\t\")\n",
    "        imdb_table_s = imdb_table[imdb_table[\"tconst\"] <= \"tt0000100\"]\n",
    "        filename.csv = filename.small\n",
    "    if check_overwrite(filename.small) == False:\n",
    "        continue\n",
    "    try:\n",
    "        imdb_table_s.to_csv(os.path.join(DATASET_LOC, filename.small), index=False)\n",
    "        print(f\"Converted {filename.tsv} to {filename.small}\")\n",
    "    except:\n",
    "        print(f\"Convert {filename.tsv} failed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bfe666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv and more data cleaning\n",
    "imdb_df = {}\n",
    "for filename in filenames.values():\n",
    "    imdb_df[filename.name] = pd.read_csv(os.path.join(DATASET_LOC, filename.csv), index_col=False)\n",
    "    temp_df = imdb_df[filename.name]\n",
    "    replace = 0\n",
    "    \n",
    "    # Replace \\N with None\n",
    "    temp_df.replace(r\"\\\\N\", None, regex=True, inplace=True)\n",
    "    replace += 1\n",
    "\n",
    "    # Replace NaN with None\n",
    "    imdb_df[filename.name] = temp_df.where(pd.notnull(temp_df), None)\n",
    "    replace += 1\n",
    "    print(f\"Made {replace} replacements on {filename.name}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "635af1e5",
   "metadata": {},
   "source": [
    "## Part 2: Inserting Data to MySQL\n",
    "\\* Start MySQL Server before running this part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe9b0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect/Create database\n",
    "cnx = connect(**CONFIG)\n",
    "cursor = cnx.cursor()\n",
    "\n",
    "try : \n",
    "    # Connect to database\n",
    "    cursor.execute(f\"USE {DB_NAME}\")\n",
    "    print(f\"Connected to {DB_NAME} database\")\n",
    "except Error as e:\n",
    "    if e.errno == errorcode.ER_BAD_DB_ERROR:\n",
    "        print(f\"Database {DB_NAME} does not exists.\")\n",
    "        \n",
    "        # Create database if not alrady exist\n",
    "        cursor.execute(f\"CREATE DATABASE {DB_NAME}\")\n",
    "        print(f\"{DB_NAME} database created.\")\n",
    "        cnx.database = DB_NAME\n",
    "    else:\n",
    "        print(f\"Failed to connect to {DB_NAME} database\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8351206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tables\n",
    "for table in CREATES:\n",
    "    create_query = CREATES[table]\n",
    "    try:\n",
    "        cursor.execute(create_query)\n",
    "        print(f\"Created table {table}\")\n",
    "    except Error as e:\n",
    "        if e.errno == errorcode.ER_TABLE_EXISTS_ERROR:\n",
    "            print(f\"{table} already exist\")\n",
    "        else:\n",
    "            print(f\"Fail to create {table}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ab0230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert_row(cursor, table, df):\n",
    "for table in INSERTS:\n",
    "    insert_query = INSERTS[table]\n",
    "    insert_rows = 0\n",
    "    try:\n",
    "        for index, row in imdb_df[table].iterrows():\n",
    "            insert_data = tuple(row)\n",
    "            cursor.execute(insert_query, insert_data)\n",
    "            cnx.commit()\n",
    "            insert_rows += 1\n",
    "    except Error as e:\n",
    "        if e.errno == errorcode.ER_DUP_ENTRY:\n",
    "            pass\n",
    "        else:\n",
    "            print(f\"Insert failed at row {index}: {insert_data}\")\n",
    "            print(e)\n",
    "    print(f\"Inserted {insert_rows} rows to {table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd7a6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closed MySQL connection\n",
    "# Always run this block when finished the program\n",
    "cursor.close\n",
    "cnx.close"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1dc8ae78",
   "metadata": {},
   "source": [
    "## Part 3 Quering the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f0a358",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"SELECT * FROM title_ratings WHERE averageRating > 3 LIMIT 5\"\n",
    "query1 = \"\"\"\n",
    "    SELECT title_basics.tconst, title_basics.primaryTitle, title_basics.startYear, CAST(title_ratings.averageRating as FLOAT)\n",
    "    FROM title_basics\n",
    "    JOIN title_ratings\n",
    "        ON title_basics.tconst = title_ratings.tconst\n",
    "    WHERE title_basics.startYear = 1896\n",
    "    ORDER BY title_ratings.averageRating DESC\n",
    "    LIMIT 10\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3f3499",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    with connect(**CONFIG) as cnx:        \n",
    "        with cnx.cursor() as cursor:\n",
    "            cnx.database = DB_NAME\n",
    "            cursor.execute(query1)\n",
    "            result = cursor.fetchall()\n",
    "            for row in result:\n",
    "                print(row)\n",
    "except Error as e:\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
