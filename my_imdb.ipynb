{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1fa240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "from urllib.request import urlretrieve\n",
    "from getpass import getpass\n",
    "\n",
    "import pandas as pd\n",
    "from mysql.connector import Error, connect, errorcode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad34efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurate MySQL connection\n",
    "\n",
    "# input username and password when run this block\n",
    "CONFIG = {\n",
    "    \"host\": \"localhost\",\n",
    "    \"user\": input(\"Enter username: \"),\n",
    "    \"password\": getpass(\"Enter password: \"),\n",
    "}\n",
    "\n",
    "# MySQL Database Name\n",
    "DB_NAME = \"my_imdb\"\n",
    "\n",
    "\n",
    "# List of datasets download links\n",
    "URLS = [\n",
    "    \"https://datasets.imdbws.com/title.basics.tsv.gz\",\n",
    "    \"https://datasets.imdbws.com/title.ratings.tsv.gz\"\n",
    "    ]\n",
    "\n",
    "\n",
    "# Dictionary of creating table queries\n",
    "CREATES = {}\n",
    "CREATES[\"title_basics\"] = \"\"\"\n",
    "    CREATE TABLE title_basics (\n",
    "        tconst varchar(20) NOT NULL,\n",
    "        titleType varchar(20),\n",
    "        primaryTitle varchar(1000),\n",
    "        originalTItle varchar(1000),\n",
    "        isAdult bool,\n",
    "        startYear smallint,\n",
    "        endYear smallint,\n",
    "        runtimeMinutes int,\n",
    "        genres varchar(255),\n",
    "        PRIMARY KEY (tconst)\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "CREATES[\"title_ratings\"] = \"\"\"\n",
    "    CREATE TABLE title_ratings (\n",
    "        tconst varchar(20) NOT NULL,\n",
    "        averageRating decimal(3, 1),\n",
    "        numVotes int,\n",
    "        PRIMARY KEY (tconst),\n",
    "        FOREIGN KEY (tconst)\n",
    "            REFERENCES title_basics(tconst)\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "# Dicionary of inseting queries\n",
    "INSERTS = {}\n",
    "INSERTS[\"title_basics\"] = \"\"\"\n",
    "    INSERT INTO title_basics\n",
    "    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "\n",
    "INSERTS[\"title_ratings\"] = \"\"\"\n",
    "    INSERT INTO title_ratings\n",
    "    VALUES (%s, %s, %s)\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424a5586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prompt skip overwriting existing file\n",
    "def check_exist(filename):\n",
    "    if os.path.exists(filename):\n",
    "        confirm = input(f\"{filename} already exist. Do you want to skip overwriting it (y/n)? \").lower()\n",
    "        if confirm.lower() == \"n\":\n",
    "            return False\n",
    "        elif confirm.lower() == \"y\":\n",
    "            return True\n",
    "        else:\n",
    "            sys.exit(\"Invalid input, please try again.\")\n",
    "    else:\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd778f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Filename class to conatins attributes of different filenames\n",
    "class Filename:\n",
    "    def __init__(self, name, url, zip, tsv, csv, small):\n",
    "        self.name = name\n",
    "        self.url = url\n",
    "        self.zip = zip\n",
    "        self.tsv = tsv \n",
    "        self.csv = csv\n",
    "        self.small = small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28c6139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a dictionary of filenames from the donwload link\n",
    "filenames = {}\n",
    "for url in URLS:\n",
    "    zip = url.rsplit(\"/\", 1)[-1]\n",
    "    tsv_matches = re.search(r\"^(.+)\\.(.+)\\.(tsv).gz$\", zip)\n",
    "    name = f\"{tsv_matches[1]}_{tsv_matches[2]}\"\n",
    "    tsv = os.path.join(name + os.extsep + \"tsv\")\n",
    "    csv = os.path.join(name + os.extsep + \"csv\")\n",
    "    small = os.path.join(name + \"_s\" + os.extsep + \"csv\")\n",
    "    filenames[name] = Filename(name, url, zip, tsv, csv, small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b3d80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Donwload datasets files from imdb website\n",
    "for filename in filenames.values():\n",
    "    if check_exist(filename.zip):\n",
    "        continue\n",
    "    try:\n",
    "        local_filename, header = urlretrieve(filename.url, filename.zip)\n",
    "        print(f\"Downloaded '{local_filename}' to {os.getcwd()}\")\n",
    "    except Error as e:\n",
    "        print(f\"Download '{local_filename}' fail\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b33729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip and rename the tsv files\n",
    "for filename in filenames.values():\n",
    "    if check_exist(filename.tsv):\n",
    "        continue\n",
    "    try:\n",
    "        with gzip.open(filename.zip, \"rb\") as f_in:\n",
    "            with open(filename.tsv, \"wb\") as f_out:\n",
    "                f_out.write(f_in.read())\n",
    "                print(f\"Extracted {filename.tsv} to {os.getcwd()}\")\n",
    "    except Error as e:\n",
    "        print(f'Extract {filename.zip} Failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6714c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning and convert tsv to csv file\n",
    "for filename in filenames.values():\n",
    "    imdb_table = pd.read_table(filename.tsv, sep=\"\\t\")\n",
    "    \n",
    "    # Data Cleaning for title_basics\n",
    "    if filename.name == \"title_basics\":\n",
    "\n",
    "        # Locate all rows with primaryTilte issues\n",
    "        title_issue_df = imdb_table[imdb_table[\"primaryTitle\"].str.contains(r\".+\\t.+\") == True]\n",
    "        \n",
    "        # If rows with primaryTilte issues exit\n",
    "        if title_issue_df.shape[0] > 0:\n",
    "            rows_fixed = 0\n",
    "            for index, row in title_issue_df.iterrows():\n",
    "                values = row.values.flatten().tolist()\n",
    "                \n",
    "                # Split the string to two columns\n",
    "                clean_titles = values[2].split(\"\\t\")\n",
    "                values[2] = clean_titles[0]\n",
    "                values.insert(3, clean_titles[1])\n",
    "\n",
    "                # Removed unnecessary NaN value at the end\n",
    "                values.pop()\n",
    "\n",
    "                # Replace the row in the table\n",
    "                imdb_table[imdb_table[\"tconst\"] == values[0]] = values\n",
    "                rows_fixed += 1\n",
    "            print(f\"Fixed {rows_fixed} row\")\n",
    "        \n",
    "    # Export csv\n",
    "    if check_exist(filename.csv):\n",
    "        continue\n",
    "    try:\n",
    "        imdb_table.to_csv(filename.csv, index=False)\n",
    "        print(f\"Converted {filename.tsv} to {filename.csv}\")\n",
    "    except:\n",
    "        print(f\"Convert {filename.tsv} failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7ad685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional\n",
    "# Reduce rows in files and convert to csv\n",
    "for filename in filenames.values():\n",
    "    imdb_table = pd.read_table(filename.tsv, sep=\"\\t\")\n",
    "    imdb_table_s = imdb_table[imdb_table[\"tconst\"] <= \"tt0000100\"]\n",
    "    filename.csv = filename.small\n",
    "    if check_exist(filename.small):\n",
    "        continue\n",
    "    try:\n",
    "        imdb_table_s.to_csv(filename.small, index=False)\n",
    "        print(f\"Converted {filename.tsv} to {filename.small}\")\n",
    "    except:\n",
    "        print(f\"Convert {filename.tsv} failed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bfe666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv and more data cleaning\n",
    "imdb_df = {}\n",
    "for filename in filenames.values():\n",
    "    imdb_df[filename.name] = pd.read_csv(filename.csv, index_col=False)\n",
    "    temp_df = imdb_df[filename.name]\n",
    "    rows_fixed = 0\n",
    "    if filename.name == \"title_basics\":\n",
    "        \n",
    "        # Replace \\N with None\n",
    "        temp_df.replace(r\"\\\\N\", None, regex=True, inplace=True)\n",
    "\n",
    "        # Replace NaN with None\n",
    "        imdb_df[filename.name] = temp_df.where(pd.notnull(temp_df), None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe9b0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect/Create database\n",
    "cnx = connect(**CONFIG)\n",
    "cursor = cnx.cursor()\n",
    "\n",
    "try : \n",
    "    # Connect to database\n",
    "    cursor.execute(f\"USE {DB_NAME}\")\n",
    "    print(f\"Connected to {DB_NAME} database\")\n",
    "except Error as e:\n",
    "    if e.errno == errorcode.ER_BAD_DB_ERROR:\n",
    "        print(f\"Database {DB_NAME} does not exists.\")\n",
    "        \n",
    "        # Create database if not alrady exist\n",
    "        cursor.execute(f\"CREATE DATABASE {DB_NAME}\")\n",
    "        print(f\"{DB_NAME} database created.\")\n",
    "        cnx.database = DB_NAME\n",
    "    else:\n",
    "        print(f\"Failed to connect to {DB_NAME} database\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8351206f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tables\n",
    "for table in CREATES:\n",
    "    create_query = CREATES[table]\n",
    "    try:\n",
    "        cursor.execute(create_query)\n",
    "        print(f\"Created table {table}\")\n",
    "    except Error as e:\n",
    "        if e.errno == errorcode.ER_TABLE_EXISTS_ERROR:\n",
    "            print(f\"{table} already exist\")\n",
    "        else:\n",
    "            print(f\"Fail to create {table}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ab0230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert_row(cursor, table, df):\n",
    "for table in INSERTS:\n",
    "    insert_rows = 0\n",
    "    try:\n",
    "        for index, row in imdb_df[table].iterrows():\n",
    "            if table == \"title_basics\":\n",
    "                insert_query = (f\"INSERT INTO {table} VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\")\n",
    "            elif table == \"title_ratings\":\n",
    "                insert_query = (f\"INSERT INTO {table} VALUES (%s, %s, %s)\")\n",
    "            insert_data = tuple(row)\n",
    "            cursor.execute(insert_query, insert_data)\n",
    "            cnx.commit()\n",
    "            insert_rows += 1\n",
    "    except Error as e:\n",
    "        if e.errno == errorcode.ER_DUP_ENTRY:\n",
    "            pass\n",
    "        else:\n",
    "            print(f\"Insert failed at row {index}: {insert_data}\")\n",
    "    print(f\"Inserted {insert_rows} rows to {table}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd7a6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Closed MySQL connection\n",
    "# Always run this block when finished the program\n",
    "cursor.close\n",
    "cnx.close"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
